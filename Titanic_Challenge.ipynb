{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition Description\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "This is my first attempt at the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for interacting with the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# packages for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data into pandas dataframes\n",
    "training = pd.read_csv('data/train.csv')\n",
    "testing = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the data, I need to begin analyzing the it.  To do this I am going to get a preview of the data using the head command. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "5                                   Moran, Mr. James    male  NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male   54      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male    2      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female   27      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female   14      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts after looking this information:\n",
    "- PassengerId: is basically an index number that will have no impact on whether or not they survived.  Will be ignored when building model\n",
    "- Survived: is the categorical feature that we are trying to test.  It is in the binary form 0=no and 1=yest\n",
    "- Pclass: lists the class of the passenger.  From the information we are given,  we know that the upper clas passengers (1) were more likely to survive than the lowest class passengers(3).  This will be used when building the model\n",
    "- Name: string in the form Last, Title First Middle (Another name). By itself is useless, but by taking information such as the last name and title, we can\n",
    "- Sex: string listing the sex of the passenger as either male or female.  Can be changed to binary 1 and 0.   It is stated that women were more likely to survive.\n",
    "- Age: gives the numerical age of the passenger. It is stated that children were more likely to survive.  \n",
    "- SibSp:  gives the number of siblings and spouses aboard\n",
    "- Parch: gives the number of parents and children aboard.  This could be combined with SibSp to get the total family size.\n",
    "- Ticket:  gives the ticket number.  \n",
    "- Fare: How much the passenger paid for the ticket.\n",
    "- Cabin: Which cabin the passenger was staying.  Is missing many values.  Given that the accident happened in the middle of the night, where the passengers were staying could \n",
    "- Embarked: Port where the passenger boarded. C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of missing values.  I am going to use the info command to figure out how much of the information is missing for each column in both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 90.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 39.2+ KB\n"
     ]
    }
   ],
   "source": [
    "training.info()\n",
    "testing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this I see that Cabin is missing too much information(~77%). I will not attempt to fill in the missing values.  There might be a way of filling in the missing information by assuming families stayed in the same cabin but I am going to stick with a simpler model for now.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to start cleaning up the data.  I am going to start with the simplest ones first. To make things take a little less time, I am going to combine the two data sets and loop through the commands for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Combined_data = [training, testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through each data set and clean up\n",
    "for data_set in Combined_data:\n",
    "    # change sex to numerical values instead of strings\n",
    "    data_set['Sex'] = data_set['Sex'].apply(lambda x: 1 if x == 'male' else 0)\n",
    "    \n",
    "    # combine sibsp and parch to get total family size.  Add 1 for the passenger\n",
    "    data_set['Family'] = data_set['SibSp'] + data_set['Parch'] + 1\n",
    "    \n",
    "    # Apply a number for the port that the passenger embarked. Since S is where the most passengers embarked\n",
    "    # I set the missing info as S\n",
    "    embarked = {'S':1, 'Q':2, 'C':3}\n",
    "    data_set['Embarked'] = data_set['Embarked'].apply(lambda x: embarked[x] if type(x)==str else 1)\n",
    "    \n",
    "#     med_fare = comb['Fare'].median()\n",
    "#     data_set['Fare'] = data_set['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the passenger's title from 'Name'\n",
    "import re\n",
    "\n",
    "def get_title(name):\n",
    "    \"\"\" Use regex to get the title form the passenger's name\"\"\"\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        title = title_search.group(1)\n",
    "        # print(title)\n",
    "        return title\n",
    "    return \"\"\n",
    "    \n",
    "for data_set in Combined_data:\n",
    "    data_set['Title'] = data_set['Name'].apply(lambda x: get_title(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f084fb049e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training['Title'].value_counts().plot(kind='bar')\n",
    "# _training = pd.DataFrame([training['Title'].value_count(), training['Survived']])\n",
    "# _training.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the chart we can see that there are four categories of importance(Mr. Miss., Mrs. Master).  Ms., Mlle., Miss., and Lady we can combine into Miss, Mme can be added to Mrs., and Sir can be added to Mr.  Everything else I will combine to Misc.  Since titles tend to correspond with age(Mr is a male adult and master is a male child), I will use median age of each group to fill in the missing ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "Master     4.0\n",
       "Misc      47.0\n",
       "Miss      21.5\n",
       "Mr        30.0\n",
       "Mrs       35.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb = pd.concat(Combined_data)\n",
    "comb.groupby(['Title'])['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_set in Combined_data:\n",
    "    # Combine to Miss\n",
    "    data_set['Title'] = data_set['Title'].replace(['Lady', 'Ms', 'Mlle'], 'Miss')\n",
    "    \n",
    "    # Combine to Mrs\n",
    "    data_set['Title'] = data_set['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Combine to Mr\n",
    "    data_set['Title'] = data_set['Title'].replace('Sir', 'Mr')\n",
    "    \n",
    "    # Combine to Misc\n",
    "    data_set['Title'] = data_set['Title'].replace(['Capt', 'Col', 'Countess', 'Don', 'Dona', \n",
    "                                                   'Dr', 'Jonkheer', 'Major', 'Rev'], 'Misc')\n",
    "    \n",
    "    # Fill missing age values with the median of the Title group\n",
    "    data_set['Age'] = data_set.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null int64\n",
      "Age            891 non-null float64\n",
      "Fare           891 non-null float64\n",
      "Embarked       891 non-null int64\n",
      "Family         891 non-null int64\n",
      "Title          891 non-null object\n",
      "dtypes: float64(2), int64(6), object(2)\n",
      "memory usage: 76.6+ KB\n"
     ]
    }
   ],
   "source": [
    "training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Data columns (total 10 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null int64\n",
      "Age            418 non-null float64\n",
      "Fare           418 non-null float64\n",
      "Embarked       418 non-null int64\n",
      "Family         418 non-null int64\n",
      "Title          418 non-null object\n",
      "Survived       418 non-null float64\n",
      "dtypes: float64(3), int64(5), object(2)\n",
      "memory usage: 35.9+ KB\n"
     ]
    }
   ],
   "source": [
    "testing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still missing a value for Fare.  I am going to replace it based off of the median of the passenger class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing['Fare'] = testing.groupby('Pclass')['Fare'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['SibSp' 'Parch' 'Ticket' 'Cabin'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-424c3046088f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Remove unnecessary features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SibSp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Parch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtesting\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SibSp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Parch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cabin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   1615\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1617\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1618\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/index.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   2801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2803\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels %s not contained in axis'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2804\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['SibSp' 'Parch' 'Ticket' 'Cabin'] not contained in axis"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary features\n",
    "training = training.drop(['SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)\n",
    "testing = testing.drop(['SibSp', 'Parch', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "      <th>Title</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name  Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    1   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)    0   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    1   \n",
       "3          895       3                              Wirz, Mr. Albert    1   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)    0   \n",
       "\n",
       "    Age     Fare  Embarked  Family Title  Survived  \n",
       "0  34.5   7.8292         2       1    Mr         0  \n",
       "1  47.0   7.0000         1       2   Mrs         0  \n",
       "2  62.0   9.6875         2       1    Mr         1  \n",
       "3  27.0   8.6625         1       1    Mr         1  \n",
       "4  22.0  12.2875         1       3   Mrs         1  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Family']\n",
    "X = training[features]\n",
    "y = training['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make the x for train & validation\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.85,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8114478114478114"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = testing[features]\n",
    "#y = testing['Survived']\n",
    "testing['Survived'] = np.round(model.predict(X),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing.to_csv('data/model_prediction.csv', columns=['PassengerId','Survived'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
